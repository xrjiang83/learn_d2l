{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learn_D2L_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xrjiang83/learn_d2l/blob/master/Learn_D2L_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpjdIb5dRjBX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f77548e1-81f7-4497-f2cf-28492a411ed6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov  4 12:22:12 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    74W / 149W |    324MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvMvKGK8Sudc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "898f9db0-1103-486b-fe50-712dd6d9340e"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqZqqpzuRyyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "e3f7595c-c673-4575-8173-d53becaecc2d"
      },
      "source": [
        "!pip install mxnet-cu100"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.5.1.post0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.17.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEM2u5P1WDgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "b186b4a5-cd95-4516-d6b5-4599d5178ca8"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.5.1.post0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHZ1_pY7R3b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A4fVK_GLwg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet.gluon import data as gdata\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize=None, root='~/.mxnet/datasets/fashion-mnist'):\n",
        "    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n",
        "    #root = os.path.expanduser(root)\n",
        "    transformer = []\n",
        "    if resize:\n",
        "      transformer += [gdata.vision.transforms.Resize(resize)]\n",
        "    transformer += [gdata.vision.transforms.ToTensor()]\n",
        "    transformer = gdata.vision.transforms.Compose(transformer)\n",
        "\n",
        "    mnist_train = gdata.vision.FashionMNIST(train=True)\n",
        "    mnist_test = gdata.vision.FashionMNIST(train=False)\n",
        "    num_workers = 0 if sys.platform.startswith('win32') else 2\n",
        "\n",
        "    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n",
        "                                  batch_size, shuffle=True,\n",
        "                                  num_workers=num_workers)\n",
        "    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n",
        "                                 batch_size, shuffle=False,\n",
        "                                 num_workers=num_workers)\n",
        "    return train_iter, test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCnl9DISMHU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 计算分类准确率\n",
        "import mxnet as mx\n",
        "from mxnet import autograd, gluon, init, nd\n",
        "from mxnet.gluon import loss as gloss, nn\n",
        "import time\n",
        "\n",
        "def evaluate_accuracy(data_iter, net, ctx) : \n",
        "  acc_sum, n = nd.array([0], ctx=ctx), 0\n",
        "  for X, y in data_iter : \n",
        "    # 如果ctx代表GPU及相应的显存，将数据复制到显存上\n",
        "    X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n",
        "    acc_sum += (net(X).argmax(axis=1) == y).sum().asscalar()\n",
        "    n += y.size\n",
        "  return acc_sum.asscalar() / n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1OJJLVVM_CC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练模型\n",
        "def train_ch5(net, train_iter, test_iter, num_epochs, batch_size, trainer, ctx) : \n",
        "  print('training on', ctx)\n",
        "  loss = gloss.SoftmaxCrossEntropyLoss()\n",
        "  for epoch in range(num_epochs) : \n",
        "    train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "    for X, y in train_iter :\n",
        "      X, y = X.as_in_context(ctx), y.as_in_context(ctx) \n",
        "      with autograd.record() : \n",
        "        y_hat = net(X)\n",
        "        l = loss(y_hat, y).sum()\n",
        "      l.backward()\n",
        "      trainer.step(batch_size)\n",
        "      y = y.astype('float32')\n",
        "      train_l_sum += l.asscalar()\n",
        "      train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "      n += y.size\n",
        "    test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
        "    print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec' % (epoch+1, train_l_sum / n, train_acc_sum / n, test_acc, time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChaHeG1JZxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################################\n",
        "##### Sect. 5.5 Below ###########################\n",
        "#####################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpePaG2hPCwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75c9ab72-f606-4aee-92de-e8d4a869be89"
      },
      "source": [
        "def try_gpu() : \n",
        "  try: \n",
        "    ctx = mx.gpu()\n",
        "    _ = nd.zeros((1,), ctx=ctx)\n",
        "  except mx.base.MXNetError: \n",
        "    ctx = mx.cpu()\n",
        "  return ctx\n",
        "\n",
        "ctx = try_gpu()\n",
        "ctx"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gpu(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2OMzNFMJfLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 通过Sequential类来实现LeNet模型\n",
        "net = nn.Sequential()\n",
        "net.add(nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'), \n",
        "    nn.MaxPool2D(pool_size=2, strides=2), \n",
        "    nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'), \n",
        "    nn.MaxPool2D(pool_size=2, strides=2), \n",
        "    # Dense会默认将（批量大小，通道，高度，宽度）形状的输入转换成（批量大小，通道*高度*宽度）形状的输入\n",
        "    nn.Dense(120, activation='sigmoid'), \n",
        "    nn.Dense(84, activation='sigmoid'), \n",
        "    nn.Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1C7v6H7TSC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 训练数据\n",
        "import sys\n",
        "batch_size = 256\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrLO9nNzVOOc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "outputId": "3c71a7ef-19ab-49c3-e322-22da920dce49"
      },
      "source": [
        "# 训练模型\n",
        "lr, num_epochs = 0.9, 50\n",
        "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "train_ch5(net, train_iter, test_iter, num_epochs, batch_size, trainer, ctx)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 2.3199, train acc 0.100, test acc 0.100, time 7.2 sec\n",
            "epoch 2, loss 1.9340, train acc 0.254, test acc 0.574, time 7.1 sec\n",
            "epoch 3, loss 0.9674, train acc 0.613, test acc 0.707, time 7.4 sec\n",
            "epoch 4, loss 0.7433, train acc 0.710, test acc 0.735, time 7.3 sec\n",
            "epoch 5, loss 0.6567, train acc 0.740, test acc 0.771, time 7.0 sec\n",
            "epoch 6, loss 0.5970, train acc 0.764, test acc 0.776, time 7.0 sec\n",
            "epoch 7, loss 0.5575, train acc 0.782, test acc 0.798, time 7.3 sec\n",
            "epoch 8, loss 0.5215, train acc 0.795, test acc 0.808, time 6.9 sec\n",
            "epoch 9, loss 0.4907, train acc 0.808, test acc 0.824, time 7.1 sec\n",
            "epoch 10, loss 0.4704, train acc 0.820, test acc 0.828, time 7.3 sec\n",
            "epoch 11, loss 0.4468, train acc 0.830, test acc 0.842, time 7.1 sec\n",
            "epoch 12, loss 0.4331, train acc 0.835, test acc 0.845, time 7.3 sec\n",
            "epoch 13, loss 0.4163, train acc 0.843, test acc 0.838, time 7.4 sec\n",
            "epoch 14, loss 0.3992, train acc 0.851, test acc 0.856, time 7.3 sec\n",
            "epoch 15, loss 0.3905, train acc 0.855, test acc 0.860, time 7.2 sec\n",
            "epoch 16, loss 0.3774, train acc 0.860, test acc 0.864, time 7.1 sec\n",
            "epoch 17, loss 0.3714, train acc 0.863, test acc 0.866, time 7.1 sec\n",
            "epoch 18, loss 0.3600, train acc 0.867, test acc 0.870, time 7.1 sec\n",
            "epoch 19, loss 0.3525, train acc 0.871, test acc 0.866, time 7.0 sec\n",
            "epoch 20, loss 0.3456, train acc 0.873, test acc 0.876, time 7.2 sec\n",
            "epoch 21, loss 0.3383, train acc 0.876, test acc 0.875, time 7.3 sec\n",
            "epoch 22, loss 0.3338, train acc 0.876, test acc 0.879, time 7.2 sec\n",
            "epoch 23, loss 0.3277, train acc 0.879, test acc 0.880, time 7.1 sec\n",
            "epoch 24, loss 0.3242, train acc 0.880, test acc 0.878, time 7.1 sec\n",
            "epoch 25, loss 0.3185, train acc 0.882, test acc 0.879, time 7.3 sec\n",
            "epoch 26, loss 0.3147, train acc 0.883, test acc 0.886, time 7.0 sec\n",
            "epoch 27, loss 0.3090, train acc 0.885, test acc 0.880, time 7.0 sec\n",
            "epoch 28, loss 0.3080, train acc 0.886, test acc 0.886, time 7.1 sec\n",
            "epoch 29, loss 0.3032, train acc 0.888, test acc 0.884, time 7.2 sec\n",
            "epoch 30, loss 0.2977, train acc 0.890, test acc 0.889, time 7.1 sec\n",
            "epoch 31, loss 0.2985, train acc 0.890, test acc 0.888, time 7.0 sec\n",
            "epoch 32, loss 0.2935, train acc 0.892, test acc 0.885, time 7.0 sec\n",
            "epoch 33, loss 0.2925, train acc 0.892, test acc 0.889, time 6.9 sec\n",
            "epoch 34, loss 0.2872, train acc 0.894, test acc 0.888, time 7.2 sec\n",
            "epoch 35, loss 0.2852, train acc 0.894, test acc 0.884, time 7.2 sec\n",
            "epoch 36, loss 0.2815, train acc 0.895, test acc 0.888, time 7.1 sec\n",
            "epoch 37, loss 0.2796, train acc 0.896, test acc 0.892, time 7.2 sec\n",
            "epoch 38, loss 0.2757, train acc 0.897, test acc 0.888, time 7.3 sec\n",
            "epoch 39, loss 0.2734, train acc 0.899, test acc 0.890, time 7.2 sec\n",
            "epoch 40, loss 0.2726, train acc 0.900, test acc 0.887, time 7.1 sec\n",
            "epoch 41, loss 0.2691, train acc 0.900, test acc 0.891, time 7.0 sec\n",
            "epoch 42, loss 0.2687, train acc 0.901, test acc 0.891, time 7.1 sec\n",
            "epoch 43, loss 0.2657, train acc 0.901, test acc 0.886, time 7.2 sec\n",
            "epoch 44, loss 0.2653, train acc 0.901, test acc 0.886, time 7.1 sec\n",
            "epoch 45, loss 0.2626, train acc 0.902, test acc 0.893, time 7.1 sec\n",
            "epoch 46, loss 0.2594, train acc 0.903, test acc 0.893, time 7.0 sec\n",
            "epoch 47, loss 0.2575, train acc 0.904, test acc 0.895, time 7.2 sec\n",
            "epoch 48, loss 0.2588, train acc 0.904, test acc 0.887, time 6.9 sec\n",
            "epoch 49, loss 0.2545, train acc 0.905, test acc 0.896, time 7.0 sec\n",
            "epoch 50, loss 0.2533, train acc 0.906, test acc 0.896, time 7.1 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHfEH-kpWk-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 练习：用CPU训练LeNet试试有多慢"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IjbLW-ooBtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###############################################################################\n",
        "######## Sect. 5.6 Below ##################################################\n",
        "###############################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prhPaQ5HoII2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "07229506-5ba6-4e77-d714-90f272420834"
      },
      "source": [
        "# 简化版AlexNet\n",
        "from mxnet import gluon, init, nd\n",
        "from mxnet.gluon import data as gdata, nn\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 读取数据集，使用Fashion-MNIST，但是图像高和宽扩大到224\n",
        "def load_data_fashion_mnist_alexnet(batch_size, resize=None, root=os.path.join('~','.mxnet','datasets','fashion-mnist')) : \n",
        "  root = os.path.expanduser(root)\n",
        "  transformer = []\n",
        "  if resize : \n",
        "    transformer += [gdata.vision.transforms.Resize(resize)]\n",
        "  transformer += [gdata.vision.transforms.ToTensor()]\n",
        "  transformer = gdata.vision.transforms.Compose(transformer)\n",
        "  mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n",
        "  mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n",
        "  num_workers = 0 if sys.platform.startswith('win32') else 4\n",
        "  train_iter = gdata.DataLoader(mnist_train.transform_first(transformer), batch_size, shuffle=True, num_workers=num_workers)\n",
        "  test_iter = gdata.DataLoader(mnist_test.transform_first(transformer), batch_size, shuffle=True, num_workers=num_workers)\n",
        "  return train_iter, test_iter\n",
        "\n",
        "batch_size = 128\n",
        "# 如果出现了内存不足，可减小batch_size或resize\n",
        "train_iter, test_iter = load_data_fashion_mnist_alexnet(batch_size, resize=224)\n",
        "\n",
        "# 定义AlexNet（简化版）\n",
        "net = nn.Sequential()\n",
        "# 使用较大的11x11窗口来捕获物体，同时使用步幅4来较大幅度减小输出高和宽。输出通道数也比LeNet大很多\n",
        "net.add(nn.Conv2D(channels=96, kernel_size=11, strides=4, activation='relu'), \n",
        "    nn.MaxPool2D(pool_size=3, strides=2), \n",
        "    # 减小卷积窗口，使用填充2来使得输入和输出的高和宽一致，且增大通道数\n",
        "    nn.Conv2D(channels=256, kernel_size=5, padding=2, activation='relu'), \n",
        "    nn.MaxPool2D(pool_size=3, strides=2), \n",
        "    # 连续三个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数\n",
        "    # 前两个卷积层不使用池化层来减小输入的高和宽\n",
        "    nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'), \n",
        "    nn.Conv2D(channels=384, kernel_size=3, padding=1, activation='relu'), \n",
        "    nn.Conv2D(channels=256, kernel_size=3, padding=1, activation='relu'), \n",
        "    nn.MaxPool2D(pool_size=3, strides=2), \n",
        "    # 这里全连接层的输出个数比LeNet大数倍。使用丢弃层来缓解过拟合\n",
        "    nn.Dense(4096, activation='relu'), nn.Dropout(0.5), \n",
        "    nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n",
        "    # 输出层。犹豫这里使用的是Fashion-MNIST，所以类别数为10，而非论文中的1000\n",
        "    nn.Dense(10))\n",
        "\n",
        "# 训练模型\n",
        "lr, num_epochs, ctx = 0.01, 5, try_gpu()\n",
        "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
        "train_ch5(net, train_iter, test_iter, num_epochs, batch_size, trainer, ctx)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu(0)\n",
            "epoch 1, loss 1.3449, train acc 0.504, test acc 0.757, time 102.5 sec\n",
            "epoch 2, loss 0.6574, train acc 0.755, test acc 0.804, time 95.1 sec\n",
            "epoch 3, loss 0.5407, train acc 0.799, test acc 0.832, time 95.1 sec\n",
            "epoch 4, loss 0.4728, train acc 0.826, test acc 0.849, time 95.2 sec\n",
            "epoch 5, loss 0.4318, train acc 0.842, test acc 0.866, time 95.2 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh9raZZhoUpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}